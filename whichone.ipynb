{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rohithbehera/whichone?scriptVersionId=133334719\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install timm\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport torch \nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport timm\nimport torch.nn as nn\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-12T16:48:36.415207Z","iopub.execute_input":"2023-06-12T16:48:36.415962Z","iopub.status.idle":"2023-06-12T16:48:57.909547Z","shell.execute_reply.started":"2023-06-12T16:48:36.415922Z","shell.execute_reply":"2023-06-12T16:48:57.908405Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.2)\nRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.15.1)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (5.4.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.14.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2023.5.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.28.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.64.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.23.5)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"data_dir = '/kaggle/input/hotelid-2022-train-images-256x256/'\ntrain_dir = '/kaggle/input/hotelid-2022-train-images-256x256/images/'\nOUTPUT_FOLDER = '/kaggle/output/'\ndf = pd.read_csv('/kaggle/input/hotelid-2022-train-images-256x256/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:57.911965Z","iopub.execute_input":"2023-06-12T16:48:57.912414Z","iopub.status.idle":"2023-06-12T16:48:57.978823Z","shell.execute_reply.started":"2023-06-12T16:48:57.91237Z","shell.execute_reply":"2023-06-12T16:48:57.977812Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Customdataset:\n    def __init__(self,data,image_path):\n        self.data = data\n        self.image_path = image_path\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self,idx):\n        item = self.data.iloc[idx]\n        item_path = self.image_path+item[\"image_id\"]\n        image = np.array(Image.open(item_path)).astype(np.uint8)\n        return {\n            \"image\":image,\n            \"target\":item[\"hotel_id_code\"]\n        }","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:57.980463Z","iopub.execute_input":"2023-06-12T16:48:57.980919Z","iopub.status.idle":"2023-06-12T16:48:57.988708Z","shell.execute_reply.started":"2023-06-12T16:48:57.980877Z","shell.execute_reply":"2023-06-12T16:48:57.987496Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df[\"hotel_id_code\"] = df[\"hotel_id\"].astype('category').cat.codes.values.astype(np.int64)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:57.992263Z","iopub.execute_input":"2023-06-12T16:48:57.993242Z","iopub.status.idle":"2023-06-12T16:48:58.041798Z","shell.execute_reply.started":"2023-06-12T16:48:57.993198Z","shell.execute_reply":"2023-06-12T16:48:58.04062Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"hotel_id_code_df = df.drop(columns=[\"image_id\"]).drop_duplicates().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:58.04399Z","iopub.execute_input":"2023-06-12T16:48:58.044829Z","iopub.status.idle":"2023-06-12T16:48:58.058886Z","shell.execute_reply.started":"2023-06-12T16:48:58.044787Z","shell.execute_reply":"2023-06-12T16:48:58.057763Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = Customdataset(df,train_dir)","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:58.061047Z","iopub.execute_input":"2023-06-12T16:48:58.06157Z","iopub.status.idle":"2023-06-12T16:48:58.066629Z","shell.execute_reply.started":"2023-06-12T16:48:58.061533Z","shell.execute_reply":"2023-06-12T16:48:58.065573Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class EmbeddingModel(nn.Module):\n    def __init__(self,number_of_classes,embedding_size,backbone_name):\n        super(EmbeddingModel,self).__init__()\n        self.backbone = timm.create_model(backbone_name,num_classes=number_of_classes,pretrained=True)\n        output_nodes = self.backbone.get_classifier().in_features\n        self.backbone.classifier = nn.Identity()\n        self.embedding = nn.Linear(3116,embedding_size)\n        self.classifier = nn.Linear(embedding_size,number_of_classes)\n    def embed_and_classify(self, x):\n        x = self.forward(x)\n        return x, self.classifier(x)\n    def forward(self, x):\n        x = self.backbone(x)\n        x = x.view(x.size(0), -1)\n        x = self.embedding(x)\n        return x   ","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:58.067997Z","iopub.execute_input":"2023-06-12T16:48:58.068915Z","iopub.status.idle":"2023-06-12T16:48:58.079832Z","shell.execute_reply.started":"2023-06-12T16:48:58.068876Z","shell.execute_reply":"2023-06-12T16:48:58.078655Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def step(args,model,loader,optimizer,criterion,scheduler,epoch):\n    losses = []\n    target_all = []\n    output_all = []\n    model.train()\n    item = tqdm(loader)\n    for i , data in enumerate(item):\n        optimizer.zero_grad()\n        inputs = data['image'].to(args.device)\n        inputs = inputs.permute(0, 3, 1, 2)\n        inputs = inputs.float()\n        targets = data['target'].to(args.device)\n        embed , output = model.embed_and_classify(inputs)\n        loss = criterion(output,targets)\n        loss.backward()\n        optimizer.step()\n        if scheduler:\n            scheduler.step()\n        losses.append(loss.item())\n        target_all.extend(targets.cpu().numpy())\n        output_all.extend(torch.sigmoid(output).detach().cpu().numpy())\n    net_loss = np.mean(losses)\n    score = np.mean(target_all == np.argmax(output_all , axis = 1))\n    print(f'at {epoch} the loss , score are {net_loss} , {score}')\n    return net_loss , score","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:58.081412Z","iopub.execute_input":"2023-06-12T16:48:58.082551Z","iopub.status.idle":"2023-06-12T16:48:58.093866Z","shell.execute_reply.started":"2023-06-12T16:48:58.08251Z","shell.execute_reply":"2023-06-12T16:48:58.092929Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def save_checkpoint(model,scheduler,optimizer,start,model_name,loss,score):\n     checkpoint = {\"epoch\": epoch,\n                  \"model\": model.state_dict(),\n                  \"scheduler\": scheduler.state_dict(),\n                  \"optimizer\": optimizer.state_dict(),\n                  \"loss\": loss,\n                  \"score\": score,\n                  }\n     torch.save(checkpoint, f\"{OUTPUT_FOLDER}checkpoint-{name}.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:58.095431Z","iopub.execute_input":"2023-06-12T16:48:58.09613Z","iopub.status.idle":"2023-06-12T16:48:58.10858Z","shell.execute_reply.started":"2023-06-12T16:48:58.096088Z","shell.execute_reply":"2023-06-12T16:48:58.107406Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def train(args,df):\n    model_name = f\"fine tuned {args.backbone}\"\n    epochs = args.epochs\n    start = 1\n    criterion = nn.CrossEntropyLoss()\n    model = EmbeddingModel(args.n_classes,args.embedding_size,args.backbone)\n    model = model.to(args.device)\n    print(model)\n    dataset = Customdataset(df,train_dir)\n    loader = DataLoader(dataset,num_workers=args.workers,batch_size=args.batch_size,shuffle=True, drop_last=True)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n                    optimizer,\n                    max_lr=args.lr,\n                    epochs=args.epochs,\n                    steps_per_epoch=len(loader),\n                    div_factor=10,\n                    final_div_factor=1,\n                    pct_start=0.1,\n                    anneal_strategy=\"cos\",\n                )\n    for start in range(1,epochs+1):\n        loss , score = step(args,model,loader,optimizer,criterion,scheduler,start)\n        if(start == epochs):\n            save_checkpoint(model,scheduler,optimizer,start,model_name,loss,score)   ","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:58.112654Z","iopub.execute_input":"2023-06-12T16:48:58.113183Z","iopub.status.idle":"2023-06-12T16:48:58.124817Z","shell.execute_reply.started":"2023-06-12T16:48:58.113142Z","shell.execute_reply":"2023-06-12T16:48:58.123567Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"%%time \n\nclass args:\n    epochs = 30\n    lr = 1e-3\n    batch_size = 64\n    workers = 2\n    embedding_size = 512\n    backbone = \"resnet34\"\n    n_classes = df[\"hotel_id_code\"].nunique()\n    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n\ntrain(args, df)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-12T16:48:58.126788Z","iopub.execute_input":"2023-06-12T16:48:58.128047Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acec5917e6e14514a349db6cbad628a9"}},"metadata":{}},{"name":"stdout","text":"EmbeddingModel(\n  (backbone): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act1): ReLU(inplace=True)\n        (aa): Identity()\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): ReLU(inplace=True)\n      )\n    )\n    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (fc): Linear(in_features=512, out_features=3116, bias=True)\n    (classifier): Identity()\n  )\n  (embedding): Linear(in_features=3116, out_features=512, bias=True)\n  (classifier): Linear(in_features=512, out_features=3116, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [11:02<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 1 the loss , score are 7.00512716968285 , 0.0914890759312321\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 2 the loss , score are 5.669170447270303 , 0.1748522564469914\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 3 the loss , score are 4.162718341480353 , 0.2786756805157593\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 4 the loss , score are 2.74160941265374 , 0.388498388252149\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 5 the loss , score are 1.6298239333581788 , 0.39031160458452724\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 6 the loss , score are 0.9117455801000568 , 0.29656160458452724\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 7 the loss , score are 0.5866223464381046 , 0.1960288323782235\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 8 the loss , score are 0.44425676778001566 , 0.13500626790830947\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 9 the loss , score are 0.3559320610987935 , 0.09632431948424068\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 10 the loss , score are 0.2926006351082578 , 0.06527578796561605\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 698/698 [10:56<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"at 11 the loss , score are 0.24842851477165448 , 0.05401593839541547\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 336/698 [05:16<05:42,  1.06it/s]","output_type":"stream"}]}]}